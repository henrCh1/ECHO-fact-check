{
  "version": "v1.44",
  "rules": [
    {
      "rule_id": "shr-00001",
      "type": "strategy",
      "condition": "IF a claim alleges media misconduct involving 'replacement' or 'manipulation' of interview content AND search results contain explicit refutations from reputable fact-checking organizations (e.g., PolitiFact, Snopes, FactCheck.org) that rate the *specific claim* as 'False' based on review of primary evidence (e.g., unedited transcripts/video).",
      "action": "PRIORITIZE these explicit refutations. The final verdict should be 'False' for the claim, overriding conclusions based solely on the existence of controversy, accusations, or less specific evidence. Ensure the agent explicitly states the fact-checker's conclusion and the primary evidence they reviewed.",
      "confidence": 0.95,
      "evidence_count": 1,
      "created_from": "case_20240520_100000",
      "created_at": "2026-01-03 18:07:12.667964",
      "parent_rule": null,
      "description": "This rule addresses a critical false negative where the agent failed to correctly identify a false claim about media content manipulation. It mandates prioritizing explicit 'False' ratings from reputable fact-checking organizations when claims of media misconduct (e.g., manipulation of interview content) are made, especially when these ratings are based on primary evidence review. This prevents misinterpretations of controversy as substantiation and ensures strong, direct evidence is given appropriate weight.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00003",
      "type": "strategy",
      "condition": "WHEN a claim includes an ambiguous date (month/day only) AND involves a public figure's role or statement, which requires temporal context for accurate evaluation",
      "action": "THEN:\n1.  Actively infer the most plausible historical context for the event by cross-referencing other elements of the claim (e.g., active political administration, specific policy context, related events).\n2.  Conduct targeted searches to verify the public figure's exact role and any attributed statements specifically within the *inferred historical timeframe*.\n3.  Avoid defaulting to the most recent or future information found for a specific title or role if it contradicts the inferred historical context.\n4.  If significant temporal ambiguity persists or different inferred years yield different results for sub-claims, this ambiguity must be explicitly acknowledged in the reasoning, and the most probable context prioritized for evaluation.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240520_100000",
      "created_at": "2026-01-03 18:14:47.970922",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to correctly infer the implied year for ambiguous dates, leading to inaccurate contextualization of public figures' roles and statements. It mandates a proactive approach to temporal disambiguation by leveraging other claim elements to establish the most plausible historical timeframe, ensuring verification occurs within that specific period, and explicitly acknowledging any unresolved ambiguity.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00004",
      "type": "strategy",
      "condition": "The claim is a compound statement involving a sensitive topic, specifically the life status of a public figure (e.g., reports of death or serious illness), where the truth of the core assertion (e.g., 'Person X is deceased') fundamentally impacts the relevance or validity of subsequent sub-claims (e.g., 'due to Y in Z hospital').",
      "action": "Prioritize the immediate and thorough verification of the core assertion regarding the public figure's life status using highly credible and direct sources. If this core assertion is definitively found to be false (e.g., the public figure is alive and well), then further detailed investigation into the dependent circumstances, causes, or locations of the non-existent event should be significantly de-prioritized or halted to ensure efficient debunking.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240729_120000",
      "created_at": "2026-01-03 18:15:58.087279",
      "parent_rule": null,
      "description": "This rule mandates prioritizing the verification of the core assertion, especially when a claim concerns the life status of a public figure within a compound statement. If the central assertion (e.g., 'Person X is deceased') is found to be false, subsequent investigation into dependent details (e.g., cause, location) should be de-prioritized or halted, as their premise is invalid. This ensures efficient debunking of sensitive, false claims by focusing on the most critical element.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00009",
      "type": "strategy",
      "condition": "When a claim involves specific numerical data, percentages, or statistics, particularly those with explicit or implied temporal contexts.",
      "action": "Mandate precise search queries for the specific numerical values and their associated context. Prioritize highly credible, primary statistical sources (e.g., government agencies, academic research, reputable fact-checking organizations specializing in data) over secondary or interpretive sources. Require rigorous temporal analysis to ensure the numerical data is compared within the correct timeframe, distinguishing between different periods, definitions, or methodologies to prevent misinterpretation and ensure accurate contextualization.",
      "confidence": 0.9,
      "evidence_count": 1,
      "created_from": "case_20240728_120000",
      "created_at": "2026-01-03 18:22:30.499341",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap in verifying claims containing numerical data or statistics. It mandates precise search queries for specific values, prioritizes highly credible statistical sources, and requires rigorous temporal contextualization to prevent misinterpretation of data across different timeframes or definitions, thereby ensuring accurate assessment of statistical claims.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00015",
      "type": "strategy",
      "condition": "When evaluating a claim that contains specific numerical data or categorical components (e.g., specific counts, percentages, named groups, or impact figures) and evidence is available for these granular details.",
      "action": "Prioritize and explicitly integrate the most granular and direct evidence available for each specific component into the reasoning. This requires citing precise figures, definitions, and sources that directly address each specific numerical or categorical detail of the claim, demonstrating a comprehensive understanding and strengthening the argument for or against the claim, even if a broader conclusion is already clear.",
      "confidence": 0.95,
      "evidence_count": 1,
      "created_from": "case_20240510_120000",
      "created_at": "2026-01-03 18:33:11.254754",
      "parent_rule": null,
      "description": "This rule addresses an opportunity to enhance the comprehensiveness and precision of evidence integration. It mandates that when a claim contains specific numerical data or categorical components, the agent must explicitly articulate and cite granular evidence for each component, rather than relying on general summations, to strengthen the reasoning and demonstrate a deeper understanding of the research, particularly in debunking false claims.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00016",
      "type": "strategy",
      "condition": "IF a claim involves a screenshot of a social media post that has been identified as fabricated AND the timestamp of the alleged post is available,",
      "action": "THEN the agent must proactively utilize archival tools (e.g., Wayback Machine, social media archives) to search for genuine posts from the alleged account at or around that specific timestamp. Subsequently, the content of any found authentic posts must be compared with the fabricated screenshot to identify specific alteration methods, such as content removal, addition, or modification. This detailed comparison should be explicitly documented in the reasoning.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240723_100000",
      "created_at": "2026-01-03 18:34:21.738549",
      "parent_rule": null,
      "description": "This rule addresses a critical gap in investigative rigor for claims involving fabricated text-based media screenshots. It mandates a deeper analysis of *how* falsification occurred by requiring the use of archival tools to find and compare genuine posts from the alleged account at the specified timestamp, thereby uncovering specific alteration methods and enhancing the comprehensiveness of debunking.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00021",
      "type": "strategy",
      "condition": "IF a complex claim has been decomposed into multiple sub-claims AND a significant proportion (e.g., >50%) of these sub-claims have been determined to be False or entirely unsubstantiated by evidence, indicating a pattern of pervasive falsehood,",
      "action": "THEN the agent must initiate a supplementary meta-analysis search for terms related to the claim's potential deliberate falsehood or origin (e.g., '[original claim keywords] hoax', '[original claim keywords] fabricated', '[original claim keywords] AI-generated rumor', '[original claim keywords] misinformation campaign') AND explicitly integrate any findings regarding the claim's deliberate nature or origin into the final reasoning and conclusion, providing a deeper explanation of *why* the claim is false beyond individual factual debunking.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240520_120000",
      "created_at": "2026-01-03 18:48:35.216426",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap by mandating a meta-analysis when a complex claim's constituent sub-claims are largely found to be false or unsubstantiated. It requires investigating the claim's origin and nature (e.g., deliberate fabrication, hoax, AI-generated content) to provide a more comprehensive debunking, moving beyond just disproving individual facts to understanding *why* the claim exists.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00026",
      "type": "strategy",
      "condition": "When a claim alleges fabrication of text-based social media screenshots and includes specific temporal details (e.g., date, time, alleged post timestamp).",
      "action": "In addition to using archival tools to find and compare genuine posts from the alleged account at the specified timestamp, the agent must proactively search for and explicitly present the genuine content (or confirmed absence thereof) from the primary source at that exact alleged time. This direct counter-factual evidence must be articulated in the reasoning to demonstrate what was actually posted, or that nothing was, at the alleged moment of fabrication, thereby providing a more thorough and undeniable debunking.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240516_100000",
      "created_at": "2026-01-03 18:57:56.855613",
      "parent_rule": "shr-00016",
      "description": "This rule refines `shr-00016` by mandating a more explicit and direct counter-factual presentation when debunking fabricated social media posts. It requires the agent to not only identify the falsification but also to actively search for and present what *was* genuinely posted (or confirm the absence of any relevant posts) from the primary source at the specified alleged timestamp. This strengthens the debunking by providing direct, primary evidence of the actual historical record, making the refutation more comprehensive and undeniable.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00027",
      "type": "strategy",
      "condition": "IF a claim asserts that visual content (e.g., 'TikTok videos') 'depicts' an event, AND evidence confirms the event occurred, AND identified visual content claiming to depict the event is significantly inauthentic or AI-generated, AND there is no clear and robust evidence of authentic visual content also depicting the event",
      "action": "THEN the 'depiction' aspect of the claim should be considered False, prioritizing the lack of authentic visual evidence over the factual occurrence of the event itself for the 'depiction' component.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240518_120000",
      "created_at": "2026-01-03 19:00:38.145245",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to correctly assess claims involving visual content 'depicting' an event, particularly when identified visual evidence is inauthentic. It mandates that if a claim asserts visual content depicts an event, and the event itself is confirmed, but the identified visual content is largely inauthentic (e.g., AI-generated) and no robust authentic visual evidence is found, then the 'depiction' aspect of the claim must be declared False. This prevents false positives by ensuring that the authenticity of the visual content is paramount for 'depiction' claims, rather than inferring authenticity from the event's occurrence or shifting the burden of proof.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00028",
      "type": "strategy",
      "condition": "IF a claim references future projections or estimates to establish a historical or temporal context (e.g., 'in 2025', 'will be the first time in X years'),",
      "action": "THEN the reasoning process must actively investigate and explicitly detail the range, consensus, or divergence of these projections from multiple credible sources, rather than merely acknowledging a general 'possibility'. This ensures a comprehensive evaluation of the predictive landscape that contextualizes the claim.",
      "confidence": 0.75,
      "evidence_count": 1,
      "created_from": "case_20240729_120000",
      "created_at": "2026-01-03 19:01:46.011023",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to comprehensively analyze claims based on future projections or estimates, especially when establishing a historical 'first time' or similar temporal context. It mandates investigating and explicitly detailing the range, consensus, or divergence among different expert forecasts from multiple credible sources, thereby moving beyond mere acknowledgment of possibility to provide a nuanced understanding of the predictive landscape.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00033",
      "type": "strategy",
      "condition": "IF (a claim describes a novel social initiative or technological innovation with a positive societal impact or a 'too good to be true' aspect) AND (initial factual verification indicates inconsistencies, lack of evidence, or outright falsehood for the claim's specific components) AND (the claim's nature suggests potential for hoaxes, exaggerations, or widespread misinformation patterns)",
      "action": "THEN (initiate supplementary search queries to investigate the claim's broader context, potential origin as a hoax, rumor patterns, or known similar projects/exaggerations in other regions. Incorporate this contextual information into the final reasoning to provide a comprehensive debunking that explains not only the factual inaccuracies but also the nature and spread of the misinformation. Search queries should include terms like 'hoax', 'rumor origin', 'misinformation pattern', 'debunked [claim subject]', or 'similar [innovation type] fraud').",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240520_120000",
      "created_at": "2026-01-03 19:11:01.297709",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to investigate the broader context and origin of misinformation for specific claim types. It mandates a meta-analysis for claims involving novel 'feel-good' social initiatives or technological innovations, especially when initial factual verification points to inaccuracies. By requiring supplementary searches into hoaxes, rumor origins, or similar misinformation patterns, it ensures a more comprehensive debunking beyond mere factual contradiction, explaining *why* the claim exists and spreads. This rule complements `shr-00021` by providing a specific trigger for this type of meta-analysis.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00036",
      "type": "strategy",
      "condition": "When a claim attributes specific content (e.g., a quote, social media post, image) to an individual, and initial verification confirms the individual did NOT produce or share that content, AND search results contain verifiable information about the content's actual origin.",
      "action": "The agent must explicitly identify and state the actual source or origin of the content, including relevant details such as the true author, platform, and date, to provide a complete and robust debunking of the misattribution. This prevents incomplete reasoning that focuses solely on disproving authorship without tracing the source of the misattributed content.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240729_120000",
      "created_at": "2026-01-03 19:15:09.786486",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to fully synthesize all available relevant evidence to provide the most complete explanation for misattributed content. It mandates that when content is misattributed to an individual, the verification process must not only confirm the subject's non-authorship but also actively seek and explicitly state the actual origin of the content if it is identifiable and verifiable through search. This enhances the comprehensiveness and robustness of the debunking by showing where the false attribution originated, moving beyond merely disproving the claim.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00037",
      "type": "strategy",
      "condition": "The claim involves a specific organization or event, asserts image authenticity, and has a temporal context of a future or recent past date.",
      "action": "The agent must prioritize and explicitly search for: (a) official statements, press releases, or denials from the involved organization; (b) detailed image forensic analysis, AI detection results, or clear visual anomaly identification specific to the image in question; and (c) concrete, verifiable counter-factuals directly addressing the alleged event or image. Additionally, the agent's final reasoning must explicitly highlight and thoroughly integrate all collected, temporally relevant, and up-to-date evidence to support the verdict.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240523_103000",
      "created_at": "2026-01-03 19:18:29.108800",
      "parent_rule": null,
      "description": "This rule addresses critical gaps in evidence collection and integration for complex claims involving image authenticity, specific organizations/events, and future or recent past temporal contexts. It mandates a rigorous evidence gathering strategy that prioritizes official organizational statements, detailed image forensics, and concrete counter-factuals. Furthermore, it requires the explicit highlighting and full integration of all relevant and up-to-date evidence in the final reasoning to ensure the most robust and comprehensive verification.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00043",
      "type": "strategy",
      "condition": "IF a claim involves sensitive topics (e.g., missing persons, deaths, major incidents in national parks/specific locations, or other high-stakes events with potential public safety implications) AND the primary evidence gathered relies solely on AI summaries or general cited segments without direct, verifiable links to authoritative primary sources (e.g., official government records, direct statements from involved organizations) or widespread, independent corroboration from multiple highly reputable mainstream news organizations;",
      "action": "THEN initiate a mandatory secondary verification phase. This phase must explicitly include: 1) Executing targeted search queries for official records (e.g., 'National Park Service incident report [event details]', 'state police press release [person/event]'); 2) Actively seeking corroboration from a minimum of two distinct, highly reputable mainstream news organizations known for their investigative rigor; AND 3) Performing explicit search queries combining key entities from the claim with terms such as 'hoax,' 'fake,' 'debunked,' or 'misinformation.' If, after this secondary phase, authoritative corroboration remains absent or credible debunking evidence is found, the claim's authenticity is critically compromised, mandating a 'False' or 'Mostly False' verdict.",
      "confidence": 0.92,
      "evidence_count": 1,
      "created_from": "case_20240515_120000",
      "created_at": "2026-01-03 19:27:53.896000",
      "parent_rule": null,
      "description": "This rule addresses a critical false positive by mandating rigorous external validity checks for sensitive claims. It requires prioritizing official government records, widespread corroboration from multiple highly reputable mainstream news organizations, and explicit searches for debunking evidence (e.g., 'hoax', 'fake') when initial evidence for sensitive topics (e.g., missing persons, deaths, major incidents) lacks authoritative primary sources. This prevents accepting internally consistent but fabricated narratives and ensures a 'False' verdict when authoritative evidence is absent or debunking efforts are found.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00045",
      "type": "strategy",
      "condition": "claim_contains_ambiguous_relative_temporal_phrase AND claim_original_context_or_timestamp_is_unknown",
      "action": "Verify the claim against both the fiscal year corresponding to the `execution_timestamp` AND the most recently completed fiscal year. Explicitly state the period(s) under evaluation and justify the choice in the reasoning.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240523_120000",
      "created_at": "2026-01-03 19:34:35.701954",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap in interpreting ambiguous relative temporal phrases (e.g., 'this year', 'current year') when the claim's original context or timestamp is unknown. It mandates a dual verification strategy: the agent must assess the claim against both the fiscal year corresponding to its `execution_timestamp` and the most recently completed fiscal year. The reasoning must explicitly state which period(s) are under evaluation and provide justification for the chosen temporal scope, thereby preventing misinterpretation and ensuring verification against the most relevant datasets.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00046",
      "type": "strategy",
      "condition": "IF a claim asserts an event, AND search results contain mentions of 'hoax claims', 'debunked rumors', or 'false reports' related to that event, AND within the same or highly credible related search results, these specific 'hoax claims', 'debunked rumors', or 'false reports' are explicitly refuted, disproven, or identified as misinformation by reputable sources, THEN the agent must recognize and resolve this conflict in evidence.",
      "action": "The agent must explicitly identify and prioritize the evidence that disproves the 'hoax claim' or 'false report'. The original event's factual status should be assessed as true or highly probable based on the debunking evidence, and the 'hoax claim' itself should be categorized as misinformation. The final reasoning must provide a clear explanation of this hierarchical evidence interpretation, detailing both the initial 'hoax claim' and its subsequent refutation.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240515_120000",
      "created_at": "2026-01-03 19:42:15.774378",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent misinterpreted mentions of 'hoax claims' or 'false reports' as evidence against an event, even when those 'hoax claims' were themselves explicitly debunked within the provided evidence. It mandates prioritizing the debunking information to establish the true factual status of the original event, preventing false negatives caused by misinterpreting meta-information about misinformation and ensuring a robust conflict resolution mechanism for such evidence patterns.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00047",
      "type": "strategy",
      "condition": "When a claim is identified as originating from a satirical source, and the specific name of that source is present in the gathered evidence, or information about its broader circulation (e.g., in multiple languages) is available.",
      "action": "The agent must explicitly name the satirical source (e.g., 'Americaâ€™s Last Line of Defense') in its reasoning. Additionally, if evidence supports it, the agent must provide broader context about the claim's spread, such as its circulation in multiple languages, to enhance the depth and specificity of the debunking explanation.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240729_120000",
      "created_at": "2026-01-03 19:43:33.215338",
      "parent_rule": null,
      "description": "This rule addresses an opportunity to enhance the comprehensiveness and specificity of debunking claims originating from satirical sources. It mandates that when a satirical origin is identified, the agent must explicitly name the specific satirical source and, if available, provide context on the claim's broader circulation to offer a more complete understanding of the misinformation's origin and spread. This complements meta-analysis rules by providing specific output requirements for satirical content.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00049",
      "type": "strategy",
      "condition": "IF (a claim is definitively proven false through strong evidence AND initial search results or the claim's context indicate widespread circulation, an unusual nature, or potential for deliberate misinformation)",
      "action": "THEN (initiate a secondary, targeted investigation step to identify the origin or nature of the false claim. This must include explicit search queries such as 'claim origin', 'claim satire', 'misinformation source', 'hoax [claim keywords]', or 'AI generated [claim keywords]'. The reasoning must explicitly incorporate this contextual information if found, explaining *why* the false claim exists and spreads, rather than merely refuting its factual accuracy.)",
      "confidence": 0.9,
      "evidence_count": 1,
      "created_from": "case_20240507_120000",
      "created_at": "2026-01-03 19:46:48.898108",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent, after definitively debunking a claim, failed to investigate the origin or nature of the falsehood. It mandates a meta-analysis for claims that are demonstrably false and show signs of widespread circulation or an unusual nature, requiring the agent to identify if the claim stems from satire, misinterpretation, deliberate hoax, or AI generation. This enhances the comprehensiveness of debunking by moving beyond mere factual contradiction to explain the 'why' and 'how' of misinformation propagation, providing valuable context to the user. This rule complements `shr-00021` and `shr-00033` by offering a broader trigger for meta-analysis on definitively false claims.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00050",
      "type": "strategy",
      "condition": "The claim explicitly references visual content, e.g., 'photo shows X,' 'image depicts Y,' 'video reveals Z,' or similar phrasing indicating visual evidence is central to the claim.",
      "action": "Proactively generate and execute targeted search queries to: 1) identify the specific visual content (e.g., image reverse search, video search), 2) verify its authenticity and original context, 3) identify the subject(s) depicted, and 4) search for any debunking information related to the visual content or its alleged depiction. All findings must be explicitly integrated into the overall reasoning to assess the visual aspect of the claim.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240729_120000",
      "created_at": "2026-01-03 19:48:49.361701",
      "parent_rule": null,
      "description": "This rule mandates a dedicated process for verifying claims that explicitly refer to visual media, ensuring the agent actively seeks, analyzes, and integrates visual evidence rather than solely relying on textual verification. It addresses a critical gap where the agent previously failed to initiate visual content analysis despite explicit prompts in the claim.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00051",
      "type": "strategy",
      "condition": "IF a claim involves an individual (speaker or referenced person) asserting they changed a specific policy or another administration's policy, AND the claim or its context implies a particular *nature* or *direction* of that change (e.g., 'ended,' 'reversed,' 'expanded'), OR there is potential for conflation of different policies or temporal misalignment in the assertion.",
      "action": "THEN the verification process must explicitly:\n1.  Identify and disambiguate the specific policy or policies being referred to, especially if ambiguous or if multiple related policies exist within the relevant domain.\n2.  Rigorously evaluate if the individual's *characterization* of the change (e.g., 'ended,' 'reversed,' 'expanded,' 'misidentified') is factually accurate and complete based on granular evidence, distinguishing the actual impact and scope of the policy change from rhetorical framing.\n3.  Ensure the evidence collected is precisely and comprehensively temporally aligned with the implied context of the claim (e.g., specific presidential terms, relevant executive orders, legislative periods), and explicitly address any temporal discrepancies or shifts in policy status over time to provide a fully contextualized assessment.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240523_120000",
      "created_at": "2026-01-03 19:50:23.490483",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to accurately assess claims about policy changes, particularly when a speaker characterizes their own actions or another administration's policy. It mandates a rigorous assessment of the specific policy(ies) involved, a direct verification of the *nature* or *direction* of the asserted change (e.g., 'ended' vs. 'expanded'), and strict temporal alignment of evidence. This prevents false positives or misleading 'True' assessments caused by conflating policies, mischaracterizing actions, or overlooking temporal nuances in policy evolution, thereby ensuring a comprehensive and accurate debunking of such claims.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00052",
      "type": "strategy",
      "condition": "IF a claim is identified as a widely circulated myth or hoax (e.g., by triggering meta-analysis rules like `shr-00021`, `shr-00033`, or `shr-00049`), AND specific evidence regarding the origin, historical context, or known spread mechanism of the myth is readily available in the `investigator_output`.",
      "action": "THEN integrate this contextual information into the final reasoning to provide a more comprehensive debunking, explicitly detailing *how* or *when* the false narrative originated. Do not omit available, relevant contextual information about the myth's origin if it enhances the explanation.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240502_120000",
      "created_at": "2026-01-03 19:51:41.400638",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to fully leverage available contextual evidence regarding the origin of widely circulated myths or hoaxes. It mandates that when a claim is identified as such (e.g., via `shr-00021`, `shr-00033`, or `shr-00049`), and specific evidence detailing the myth's origin, historical context, or spread mechanism is readily present in the `investigator_output`, this information *must* be integrated into the final reasoning. This ensures a comprehensive debunking that explains not only *what* is false but also *how* and *why* the misinformation originated and circulated, enhancing the overall robustness and educational value of the assessment.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00054",
      "type": "strategy",
      "condition": "IF a claim explicitly asserts the authenticity of a specific video or image depicting an event, particularly when the claim's veracity hinges on the visual content itself.",
      "action": "THEN prioritize targeted searches for media forensics, AI/deepfake detection analyses, or reputable fact-checks specifically addressing the authenticity of that exact video/image. If evidence indicates the specific visual media is AI-generated, manipulated, or fabricated, conclude the claim is False, explicitly stating the specific findings on the media's inauthenticity and clarifying that the existence of general real-world events or similar narratives does not validate the specific visual media's authenticity.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240520_120000",
      "created_at": "2026-01-03 19:57:58.169612",
      "parent_rule": null,
      "description": "This rule addresses a critical false positive where the agent failed to identify fabricated visual media, especially AI-generated content, by conflating the authenticity of a specific video/image with the existence of similar real-world events. It mandates that when a claim asserts the authenticity of specific visual media depicting an event, the primary verification must focus on authenticating *that specific media itself* through targeted searches for media forensics, AI/deepfake detection, or reputable fact-checks. If the media is found to be fabricated, the claim asserting its authenticity is False, regardless of whether similar events have occurred, thereby preventing misleading conclusions based on inauthentic visual evidence. This rule complements `shr-00027` by providing a proactive search strategy and explicitly warning against the conflation pitfall.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00055",
      "type": "strategy",
      "condition": "IF a claim involves visual media asserting to depict natural phenomena from an unusual or specific perspective (e.g., a passenger plane above hurricane clouds), AND the `investigator_output` contains evidence (e.g., expert analysis, factual data) detailing the physical implausibility or inconsistency of the visual content's depiction (e.g., discrepancies with known altitudes, flight mechanics, or scientific principles), AND the visual media's inauthenticity has been established by other means (e.g., AI-detection, fact-checker debunking).",
      "action": "THEN the agent must explicitly integrate and articulate these physical inconsistencies and their implications into the final reasoning, explaining *how* the visual content contradicts real-world physical laws, operational procedures, or scientific observations, to provide a more comprehensive and robust explanation for the media's inauthenticity. This integration should occur even if direct debunking labels (e.g., 'AI-generated') are already present.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240523_100000",
      "created_at": "2026-01-03 19:59:27.430680",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to fully integrate supporting contextual evidence detailing physical implausibility, even when direct debunking (e.g., 'AI-generated') was present. It mandates that when visual media claims depict natural phenomena from unusual perspectives, and evidence of physical inconsistencies or implausibility is found, this information must be explicitly articulated in the reasoning. This ensures a multi-faceted, robust, and convincing explanation for the media's inauthenticity, moving beyond mere factual contradiction to explain *why* the depiction is impossible or inconsistent with reality.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00056",
      "type": "strategy",
      "condition": "IF a claim involves visual or audio media that is alleged or suspected to be fake, manipulated, or AI-generated, OR if the event depicted is found to be non-existent or fabricated, thereby raising a strong suspicion of media inauthenticity.",
      "action": "THEN the search strategy must include explicit queries designed to find direct evidence of media manipulation, fabrication, or inauthenticity (e.g., 'AI deepfake signs [person/event]', 'video manipulation evidence [claim]', 'official debunking [video/audio name]', 'visual artifacts [video/audio description]', 'image forensics [image content]'). AND the reasoning process must prioritize, explicitly detail, and cite any such direct evidence of fabrication (e.g., AI artifacts, deepfake indicators, inconsistencies, official debunking statements) when evaluating the media's authenticity, rather than solely inferring inauthenticity from the non-occurrence of the depicted event. This direct evidence should be integrated with existing visual media verification rules such as `shr-00050`, `shr-00054`, `shr-00027`, and `shr-00055`.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240515_120000",
      "created_at": "2026-01-03 20:02:21.729328",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent inferred media inauthenticity solely from the non-occurrence of a depicted event, rather than actively seeking direct evidence of manipulation. It mandates that when visual or audio media is alleged or suspected to be fake, the verification process must include explicit search queries for direct evidence of fabrication (e.g., AI artifacts, deepfake indicators, forensic analysis, official debunking statements). The reasoning must prioritize and explicitly detail this direct evidence to provide a robust and comprehensive justification for media authenticity judgments, complementing existing rules for visual media verification and enhancing the ability to debunk sophisticated misinformation.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00058",
      "type": "strategy",
      "condition": "IF a claim has been definitively identified as False due to misinformation, fabrication, or a hoax (e.g., viral rumor, AI-generated content, satire) by existing meta-analysis rules (e.g., shr-00021, shr-00033, shr-00049).",
      "action": "THEN the agent must proactively investigate and explicitly report specific sources of propagation (e.g., named social media pages, specific websites, content creators), discernible motives behind the misinformation (e.g., ad revenue, clickbait, political agenda, humor), and, if applicable, categorize the misinformation type (e.g., 'glurge', 'urban legend', 'deepfake') based on available evidence, integrating these details into the final reasoning.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240502_100000",
      "created_at": "2026-01-03 20:06:52.108024",
      "parent_rule": null,
      "description": "This rule enhances the comprehensiveness of debunking by mandating detailed meta-analysis output for definitively false claims. When a claim is identified as misinformation or fabricated, it requires the agent to proactively identify and articulate specific propagators, their discernible motives, and the type of misinformation, providing a deeper understanding of the falsehood's origin and spread beyond mere factual contradiction. This complements existing meta-analysis rules (e.g., `shr-00021`, `shr-00033`, `shr-00049`, `shr-00052`) by specifying required output granularity.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00059",
      "type": "strategy",
      "condition": "When a claim is definitively identified as false or fabricated, and shows signs of widespread circulation, unusual nature, or explicit visual/textual manipulation.",
      "action": "The agent must proactively identify specific propagators, their discernible motives (e.g., ad revenue, engagement bait), and the precise type of misinformation. This includes actively searching for and detailing explicit signs of fabricated content (e.g., characteristics of AI-generated images or text artifacts, manipulated timestamps) and identifying common misinformation patterns such as 'glurge' (sentimental hoaxes), celebrity death hoaxes, or other known viral falsehoods. This comprehensive meta-analysis, explaining *what* is false, *how* it was fabricated, and *why* it originated/spread, must be fully integrated into the final reasoning.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240520_120000",
      "created_at": "2026-01-03 20:08:25.864087",
      "parent_rule": "shr-00058",
      "description": "This rule refines `shr-00058` by mandating a more granular and proactive meta-analysis for definitively false claims. It requires the agent to not only identify propagators and motives but also to actively search for and articulate specific signs of fabricated content (e.g., AI-generated artifacts) and common misinformation patterns (e.g., 'glurge', celebrity hoaxes), providing a comprehensive explanation of the falsehood's origin, fabrication methods, and spread.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00060",
      "type": "strategy",
      "condition": "When a claim involves visual media that is definitively identified as AI-generated or significantly manipulated, leading to a 'False' assessment of its authenticity or depiction.",
      "action": "The agent's reasoning must explicitly include: (1) A disclaimer acknowledging the inherent limitations and potential unreliability of general-purpose AI detection tools, especially if such tools were referenced or are commonly used in the public discourse surrounding the claim. (2) Specific visual inconsistencies, artifacts, or 'tells' within the media itself that indicate AI generation or manipulation, drawing from credible forensic analysis or detailed fact-checker reports. (3) Contextual information about the claim's dissemination, including its timeline of virality, specific social media platforms involved, and any relevant real-world events or broader misinformation patterns that may have fueled its spread.",
      "confidence": 0.9,
      "evidence_count": 1,
      "created_from": "case_20240723_100000",
      "created_at": "2026-01-03 20:10:22.004178",
      "parent_rule": "shr-00059",
      "description": "This rule refines `shr-00059` by mandating a highly granular and comprehensive reasoning output specifically for claims involving AI-generated or manipulated visual media. It requires explicit articulation of AI detection tool limitations, detailed visual forensic 'tells', and thorough contextualization of the misinformation's spread, ensuring a robust and educational debunking by addressing a critical gap in reasoning depth for such claims.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00064",
      "type": "strategy",
      "condition": "IF a claim involves a significant event (e.g., death, major appointment, major policy change) concerning a public figure or organization, AND IF evidence consistently places this event in the future relative to the execution timestamp, AND IF the primary supporting evidence consists of AI summaries, general search results, or secondary reports lacking direct primary source links.",
      "action": "THEN: 1. Initiate targeted search queries for 'death hoax [figure]', 'fabricated rumor [figure/organization]', 'AI generated [figure] news', 'disinformation about [figure/organization]', '[event] misinformation'. 2. Prioritize identifying and analyzing the *ultimate source* of the claims (e.g., specific websites, social media pages, original articles) over intermediary summaries or secondary reports, even if these intermediaries are initially marked 'high credibility'. 3. Evaluate the ultimate source for signs of low credibility, known hoax dissemination, AI-generated content, or satirical intent. 4. Explicitly integrate findings about the nature and origin of the falsehood, and adjust the overall evidence credibility assessment based on the ultimate source's reliability.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240515_120000",
      "created_at": "2026-01-03 20:17:14.149670",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to proactively investigate the nature and origin of suspicious claims, especially when significant future events are reported as fact and supported primarily by intermediary sources like AI summaries or general search results. It mandates triggering deeper meta-analysis and scrutinizing ultimate sources, rather than relying solely on temporal discrepancies or the perceived credibility of summarization services, to uncover hoaxes, AI-generated content, or disinformation. This enhances the application of existing meta-analysis rules (e.g., shr-00049, shr-00058, shr-00059) by providing a specific, high-priority trigger for such investigations and refining source credibility assessment.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00068",
      "type": "strategy",
      "condition": "IF a claim involves a well-known, persistent conspiracy theory with specific, commonly cited false premises (e.g., allegations of document forgery, altered imagery, or historical revisionism) and the claim is determined to be false.",
      "action": "THEN the reasoning MUST explicitly address and refute these specific false premises, detailing how each is debunked using targeted, authoritative evidence (e.g., official clarifications on document authenticity, historical records, expert forensic analysis reports, or direct counter-evidence). This enhances the comprehensiveness of the debunking and preemptively counters specific misinformation tactics.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240729_103000",
      "created_at": "2026-01-03 20:25:11.721689",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent, while correctly identifying a claim related to a persistent conspiracy theory as false, failed to explicitly refute the specific, commonly cited false premises underpinning the conspiracy. It mandates a deeper, more granular debunking strategy that directly confronts these specific allegations using targeted, authoritative evidence, thereby providing a more robust, comprehensive, and effective counter to entrenched misinformation. This rule complements existing meta-analysis rules (e.g., shr-00021, shr-00049, shr-00052, shr-00058, shr-00059) by specifying the depth of factual counter-argumentation required for such claims.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00069",
      "type": "strategy",
      "condition": "IF a claim involves a specific numerical quantity of items or a list (e.g., 'seven wars'), AND the `investigator_output`'s `raw_search_responses` contain a complete or partial list of these items along with expert assessments regarding them",
      "action": "THEN the agent must meticulously extract and integrate all granular details for each item from the `raw_search_responses` into the final `evidence` block. The `reasoning` must then granularly evaluate each item against the claim, explicitly using all available corroborating or refuting evidence. The agent must not state that information (e.g., a list or specific items) is incomplete or impossible to verify if it was demonstrably present in the `raw_search_responses`.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240726_120000",
      "created_at": "2026-01-03 20:26:55.919891",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning and evidence integration gap where the agent failed to fully leverage available granular details from `raw_search_responses` for claims involving specific numerical quantities or lists. It mandates meticulous extraction and integration of all relevant item-specific evidence into the `evidence` block, ensuring granular evaluation in the reasoning. Crucially, it prohibits stating that information is incomplete or unverifiable if it was actually present in the `raw_search_responses`, thereby preventing erroneous conclusions based on perceived lack of evidence when it was already collected. This rule strengthens the application of `shr-00015` and `shr-00061` for such specific claim structures.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00070",
      "type": "strategy",
      "condition": "IF a claim is identified as a social media hoax or scam involving the deceptive use of images, AND credible evidence explicitly identifying the real person in the image along with their actual status (e.g., 'The image used is of [Real Name], who is [actual status], not the alleged [Hoax Name].') is present in the investigator_output or raw_search_responses.",
      "action": "THEN the reasoning MUST actively extract and explicitly include this specific identification and status in the final debunking, clearly stating the true identity and status of the person depicted in the falsely used image to provide a precise and impactful refutation of the deceptive tactic.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20240728_120000",
      "created_at": "2026-01-03 20:28:33.401501",
      "parent_rule": null,
      "description": "This rule addresses a critical gap in debunking image-based hoaxes and scams by mandating the explicit identification of individuals whose images are deceptively used. When a claim is identified as a hoax involving misattributed images, and credible evidence reveals the true identity and status of the person depicted, this rule requires the agent to actively extract and integrate this specific information into the debunking. This enhances the precision, impact, and comprehensiveness of the refutation by directly countering the deceptive visual tactic. It complements existing meta-analysis and visual media verification rules (e.g., shr-00049, shr-00052, shr-00054, shr-00056, shr-00059, shr-00066) by adding a specific output requirement for this common misinformation pattern.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00071",
      "type": "strategy",
      "condition": "IF a claim attributes a future numerical projection (e.g., deficit, spending, growth) to a specific past or present political administration,",
      "action": "THEN the agent must explicitly investigate and state the precise temporal window (e.g., fiscal year, calendar year) of that projection, determine which administration's tenure it predominantly covers, and integrate this information into the reasoning to verify the accuracy of the attribution. This requires looking beyond the claim's surface attribution to the actual temporal scope of the projection.",
      "confidence": 0.85,
      "evidence_count": 1,
      "created_from": "case_20240726_120000",
      "created_at": "2026-01-03 20:29:51.605591",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to accurately attribute future numerical projections to the correct political administration. It mandates explicitly identifying the temporal window of such projections and determining which administration's tenure they primarily span, thereby ensuring comprehensive and precise debunking of misattributions.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00073",
      "type": "strategy",
      "condition": "IF a claim asserts an institution refuses to disclose specific information about a particular group (e.g., student identities, financial data, demographic details), and the core assertion of refusal is found to be false or misleading.",
      "action": "THEN the reasoning must explicitly investigate and integrate details about: 1) Any pre-existing, routine data collection by relevant government agencies or third parties concerning the information in question, which may undermine the premise of a unique 'refusal to tell us'. 2) The specific nature and extent of any information the institution *did* provide or offer to provide, even if it disputed broader or additional requests. This contextualization is crucial to accurately frame the alleged 'refusal' and strengthen the comprehensive refutation.",
      "confidence": 0.8,
      "evidence_count": 1,
      "created_from": "case_20231027_123456",
      "created_at": "2026-01-03 20:37:12.362761",
      "parent_rule": null,
      "description": "This rule addresses a critical reasoning gap where the agent failed to fully leverage available contextual evidence when debunking claims of institutional refusal to disclose information. It mandates a comprehensive refutation strategy that includes detailing existing government data collection related to the information and specifying any partial disclosures made by the institution. This ensures a more robust, nuanced, and persuasive debunking by directly addressing the implied context of the 'refusal' and preventing superficial assessments.",
      "active": true,
      "memory_type": "detection"
    },
    {
      "rule_id": "shr-00074",
      "type": "strategy",
      "condition": "When a claim is identified as 'extraordinary' (e.g., asserting a large numerical impact, a novel mechanism, or a significant, uncorroborated event), especially if it contains 'specific numerical data' (e.g., 'X lives saved', 'Y amount of drugs) or asserts a 'causal link' between actions and outcomes, and initial searches for supporting evidence yield little to no credible substantiation.",
      "action": "For such claims, the agent must execute a comprehensive and proactive debunking strategy including:\n1.  **Numerical Plausibility Check**: Compare claimed numerical figures against verifiable baseline statistics (e.g., annual U.S. drug overdose deaths, typical drug seizure quantities, relevant population sizes) to assess their real-world feasibility.\n2.  **Causal Chain Analysis**: Investigate the validity, existence, and logical sequence of each asserted link in the causal chain using authoritative external data (e.g., primary sources of substances, main entry points, specific intervention mechanisms) and actively search for and integrate expert opinions or scientific consensus on the efficacy or plausibility of the asserted causal relationship (e.g., 'drug interdiction effectiveness research', 'lethal dose conversion limitations').\n3.  **Proactive Debunking Search**: Conduct targeted searches for contradictory or debunking evidence (e.g., 'fact check [claimant] [numerical value] lives saved', 'evidence of [drug type] from [claimed source] hoax') to actively disconfirm the claim.\n4.  **Highlight Missing Details**: Explicitly document and highlight the absence of crucial specific details (e.g., exact drug type, precise quantity, methodology of calculation, specific dates/locations, verifiable sources) from the claiming party that would be necessary to substantiate the claim.",
      "confidence": 0.92,
      "evidence_count": 1,
      "created_from": "case_20240728_100000",
      "created_at": "2026-01-03 20:38:55.640643",
      "parent_rule": "shr-00043",
      "description": "This rule addresses a critical reasoning gap for extraordinary claims, particularly those involving numerical data or causal assertions. It mandates a robust, proactive debunking strategy that goes beyond mere absence of evidence. This includes numerical plausibility checks against baselines, thorough causal chain analysis with expert opinion integration, active searching for contradictory evidence when support is lacking, and explicitly highlighting critical missing details from the claimant. This significantly enhances the comprehensiveness and rigor of debunking for high-stakes, sensitive claims, refining the general principles of 'shr-00043'.",
      "active": true,
      "memory_type": "detection"
    }
  ],
  "last_updated": "2026-01-03 20:38:55.642858",
  "total_cases_processed": 58
}